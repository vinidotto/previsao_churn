{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMK3nUF3ZeY9"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle kagglehub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import kagglehub\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "print(\"Bibliotecas importadas\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando o dataset\n",
        "df = pd.read_csv('dataset.csv')\n",
        "print(\"Dataset 'dataset.csv' carregado com sucesso!\")\n",
        "\n",
        "print(\"\\nVisualização:\")\n",
        "display(df.head())"
      ],
      "metadata": {
        "id": "M5B0zzQcZiV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_processed = df.copy()\n",
        "\n",
        "# A coluna TotalCharges tem alguns espaços vazios que precisam ser tratados.\n",
        "df_processed['TotalCharges'] = pd.to_numeric(df_processed['TotalCharges'], errors='coerce')\n",
        "median_value = df_processed['TotalCharges'].median() # Calcula a mediana da coluna\n",
        "df_processed['TotalCharges'].fillna(median_value, inplace=True)\n",
        "\n",
        "# Removendo a coluna customerID, pois não é relevante\n",
        "df_processed.drop('customerID', axis=1, inplace=True)\n",
        "\n",
        "# Separando as features (X) e a variável alvo (y)\n",
        "X = df_processed.drop('Churn', axis=1)\n",
        "y = df_processed['Churn'].apply(lambda x: 1 if x == 'Yes' else 0) # Convertendo 'Yes'/'No' para 1/0\n",
        "\n",
        "# Identificando colunas numéricas e categóricas para o pré-processamento\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# transformador para aplicar OneHotEncoding nas colunas categóricas e StandardScaler nas colunas numéricas.\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ])\n",
        "\n",
        "X_processed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Dividindo os dados em conjuntos de treino e teste 80% treino, 20% teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42, stratify=y)\n"
      ],
      "metadata": {
        "id": "nKwWkM_haw5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construção do modelo sequencial\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(units=32, activation='relu', input_shape=[X_train.shape[1]]),\n",
        "    keras.layers.Dropout(0.3),\n",
        "\n",
        "    # Camada oculta\n",
        "    keras.layers.Dense(units=16, activation='relu'),\n",
        "    keras.layers.Dropout(0.2),\n",
        "\n",
        "    # A saída será uma probabilidade entre 0 e 1\n",
        "    keras.layers.Dense(units=1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compilando modelo\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "0aO2z3y9azc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treino modelo\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "# Aplicamos o SMOTE APENAS nos dados de treino, não pode ser nos de validação ou de teste\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_resampled,\n",
        "    y_train_resampled,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "VQ3VX0Cea1pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliando o modelo com o conjunto de teste\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"\\nAcurácia no conjunto de teste: {accuracy:.4f}\")\n",
        "\n",
        "y_pred_proba = model.predict(X_test)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int).flatten() # Convertendo probabilidades para 0 ou 1\n",
        "\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['No Churn', 'Churn']))\n",
        "\n",
        "print(\"\\nMatriz de Confusão:\")\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Churn', 'Churn'], yticklabels=['No Churn', 'Churn'])\n",
        "plt.xlabel('Previsão')\n",
        "plt.ylabel('Verdadeiro')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hHw0WRM4a2nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dea8cca5"
      },
      "source": [
        "# Exemplo de dados de um novo cliente.\n",
        "novo_cliente_data = {\n",
        "    'gender': ['Female'],\n",
        "    'SeniorCitizen': [0],\n",
        "    'Partner': ['Yes'],\n",
        "    'Dependents': ['No'],\n",
        "    'tenure': [1],\n",
        "    'PhoneService': ['No'],\n",
        "    'MultipleLines': ['No phone service'],\n",
        "    'InternetService': ['Yes'],\n",
        "    'OnlineSecurity': ['No'],\n",
        "    'OnlineBackup': ['Yes'],\n",
        "    'DeviceProtection': ['No'],\n",
        "    'TechSupport': ['Yes'],\n",
        "    'StreamingTV': ['Yes'],\n",
        "    'StreamingMovies': ['No'],\n",
        "    'Contract': ['Month-to-month'],\n",
        "    'PaperlessBilling': ['Yes'],\n",
        "    'PaymentMethod': ['Electronic check'],\n",
        "    'MonthlyCharges': [29.85],\n",
        "    'TotalCharges': [29.85]\n",
        "}\n",
        "\n",
        "novo_cliente_df = pd.DataFrame(novo_cliente_data)\n",
        "\n",
        "# Aplicando o mesmo pré-processamento usado nos dados de treino\n",
        "novo_cliente_processed = preprocessor.transform(novo_cliente_df)\n",
        "\n",
        "previsao_proba = model.predict(novo_cliente_processed)\n",
        "\n",
        "# Convertendo a probabilidade para 0 ou 1\n",
        "previsao_churn = (previsao_proba > 0.5).astype(int).flatten()\n",
        "\n",
        "if previsao_churn[0] == 1:\n",
        "    print(f\"A previsão de churn para este cliente é: Sim (Probabilidade: {previsao_proba[0][0]:.4f})\")\n",
        "else:\n",
        "    print(f\"A previsão de churn para este cliente é: Não (Probabilidade: {previsao_proba[0][0]:.4f})\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}